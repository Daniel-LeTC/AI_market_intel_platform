import pandas as pd
import plotly.express as px
import streamlit as st

from scout_app.ui.common import (
    get_evidence_data,
    get_precalc_stats,
    get_raw_sentiment_data,
    get_weighted_sentiment_data,
    query_df,
    query_one,
    time_it,
)


@st.fragment
@time_it
def render_xray_tab(selected_asin):
    """
    Renders Tab 2: Customer X-Ray (Sentiment, Ratings, Evidence)
    """
    precalc = get_precalc_stats(selected_asin)
    
    # --- MODE SELECTION (Robust State) ---
    mode_key = f"xray_view_mode_final"
    if mode_key not in st.session_state:
        st.session_state[mode_key] = "üì¶ T·ª´ng s·∫£n ph·∫©m"

    view_mode = st.radio(
        "Ch·∫ø ƒë·ªô hi·ªÉn th·ªã (Display Mode):",
        ["üì¶ T·ª´ng s·∫£n ph·∫©m", "üî• So s√°nh th·ªã tr∆∞·ªùng (Top 50)"],
        index=0 if st.session_state[mode_key] == "üì¶ T·ª´ng s·∫£n ph·∫©m" else 1,
        horizontal=True,
        help="So s√°nh s·∫£n ph·∫©m hi·ªán t·∫°i ho·∫∑c xem b·ª©c tranh to√†n c·∫£nh 50 ƒë·ªëi th·ªß h√†ng ƒë·∫ßu.",
        key="xray_radio_widget"
    )
    # Sync widget back to state
    st.session_state[mode_key] = view_mode

    if "th·ªã tr∆∞·ªùng" in view_mode:
        render_mass_mode(selected_asin)
        return

    c1, c2 = st.columns([2, 1])
    with c1:
        st.subheader("üìä Aspect Sentiment Analysis")

        # --- TOGGLE SWITCH ---
        analysis_mode = st.radio(
            "Ch·∫ø ƒë·ªô ph√¢n t√≠ch (Analysis Mode):",
            ["T·∫ßn su·∫•t (Volume)", "T√°c ƒë·ªông (Impact Score)"],
            horizontal=True,
            help="""
            **T·∫ßn su·∫•t (Volume):** Kh√°ch h√†ng nh·∫Øc ƒë·∫øn c√°i g√¨ nhi·ªÅu nh·∫•t? (Nhi·ªÅu ch∆∞a ch·∫Øc ƒë√£ quan tr·ªçng).\n
            **T√°c ƒë·ªông (Impact):** Y·∫øu t·ªë n√†o quy·∫øt ƒë·ªãnh vi·ªác kh√°ch cho 1 sao (Ti√™u c·ª±c) hay 5 sao (T√≠ch c·ª±c)?
            """,
        )

        if "T√°c ƒë·ªông" in analysis_mode:
            # PRE-CALC WEIGHTED
            if precalc and "sentiment_weighted" in precalc:
                df_w = pd.DataFrame(precalc["sentiment_weighted"])
                st.caption("‚ö° Source: Pre-calculated (Instant)")
            else:
                # Fallback needed if using old logic? For now, assume stats are updated.
                # If fallback is needed, we should implement get_weighted_sentiment_data to match new logic
                # But to save time, let's rely on re-calc.
                st.warning("Please re-calculate stats for this ASIN to see new Impact Chart.")
                df_w = pd.DataFrame()

            if not df_w.empty:
                # Sort by Total Volume (Impact Magnitude)
                df_w = df_w.sort_values("total_impact_vol", ascending=False)

                # Rename cols for display
                df_disp = df_w.rename(
                    columns={
                        "aspect": "Kh√≠a c·∫°nh",
                        "est_positive": "üòç Khen (Est.)",
                        "est_negative": "üò† Ch√™ (Est.)",
                        "net_impact": "‚öñÔ∏è Net Impact",
                    }
                )

                st.dataframe(
                    df_disp[["Kh√≠a c·∫°nh", "üòç Khen (Est.)", "üò† Ch√™ (Est.)", "‚öñÔ∏è Net Impact"]],
                    use_container_width=True,
                    column_config={
                        "üòç Khen (Est.)": st.column_config.ProgressColumn(
                            "üòç Khen (Est.)",
                            format="%d",
                            min_value=0,
                            max_value=int(df_w["est_positive"].max()),
                            help="∆Ø·ªõc t√≠nh s·ªë kh√°ch h√†ng H√ÄI L√íNG v·ªÅ kh√≠a c·∫°nh n√†y.",
                        ),
                        "üò† Ch√™ (Est.)": st.column_config.ProgressColumn(
                            "üò† Ch√™ (Est.)",
                            format="%d",
                            min_value=0,
                            max_value=int(df_w["est_negative"].max()),
                            help="∆Ø·ªõc t√≠nh s·ªë kh√°ch h√†ng TH·∫§T V·ªåNG v·ªÅ kh√≠a c·∫°nh n√†y.",
                        ),
                        "‚öñÔ∏è Net Impact": st.column_config.NumberColumn(
                            "‚öñÔ∏è Net Impact", format="%d", help="Hi·ªáu s·ªë (Khen - Ch√™). D∆∞∆°ng = L·ª£i th·∫ø. √Çm = V·∫•n ƒë·ªÅ."
                        ),
                    },
                    hide_index=True,
                )

                st.info("""
                ‚ÑπÔ∏è **C√°ch t√≠nh s·ªë li·ªáu ∆∞·ªõc t√≠nh (Estimated Impact):**
                
                H·ªá th·ªëng s·ª≠ d·ª•ng t·ª∑ l·ªá xu·∫•t hi·ªán trong m·∫´u review (Sample) ƒë·ªÉ suy r·ªông ra to√†n b·ªô kh√°ch h√†ng th·ª±c t·∫ø (Population) theo t·ª´ng m·ª©c sao.
                
                **V√≠ d·ª• minh h·ªça:**
                - S·∫£n ph·∫©m c√≥ **10,000 rating** (trong ƒë√≥ **5% l√† 1 sao** = 500 kh√°ch).
                - Ch√∫ng t√¥i ph√¢n t√≠ch m·∫´u **100 review 1 sao**, th·∫•y c√≥ **20 ng∆∞·ªùi** ch√™ "V·∫£i r√°ch" (T·ª∑ l·ªá 20% trong nh√≥m 1 sao).
                - üëâ H·ªá th·ªëng ∆∞·ªõc t√≠nh: C√≥ kho·∫£ng **100 kh√°ch h√†ng** (500 x 20%) th·ª±c t·∫ø ƒëang g·∫∑p v·∫•n ƒë·ªÅ "V·∫£i r√°ch".
                
                *Vi·ªác t√≠nh to√°n ƒë∆∞·ª£c th·ª±c hi·ªán ƒë·ªôc l·∫≠p cho t·ª´ng nh√≥m sao (1-5) r·ªìi t·ªïng h·ª£p l·∫°i, gi√∫p b·∫°n h√¨nh dung quy m√¥ th·∫≠t s·ª± c·ªßa v·∫•n ƒë·ªÅ tr√™n to√†n b·ªô d·ªØ li·ªáu.*
                """)
            else:
                st.warning("Weighted Analysis unavailable.")

        else:
            # PRE-CALC RAW
            if precalc and "sentiment_raw" in precalc:
                df_aspect = pd.DataFrame(precalc["sentiment_raw"])
                st.caption("‚ö° Source: Pre-calculated (Instant)")
            else:
                df_aspect = get_raw_sentiment_data(selected_asin)
                st.caption("üê¢ Source: Live Query (Slow - Cache Miss)")

            if not df_aspect.empty:
                fig_aspect = px.bar(
                    df_aspect,
                    y="aspect",
                    x=["positive", "negative"],
                    orientation="h",
                    title="T·∫ßn su·∫•t nh·∫Øc ƒë·∫øn (Review Volume)",
                    labels={"value": "S·ªë l·∫ßn nh·∫Øc (Mentions)", "variable": "C·∫£m x√∫c", "aspect": "Kh√≠a c·∫°nh"},
                    color_discrete_map={"positive": "#00CC96", "negative": "#EF553B"},
                    height=400,
                )
                st.plotly_chart(fig_aspect, use_container_width=True)
            else:
                st.info("Not enough data for Aspect Analysis.")

    with c2:
        st.subheader("‚ö†Ô∏è Real Rating Distribution")
        # Fetch JSON breakdown from Products
        dist_json = query_one("SELECT rating_breakdown FROM products WHERE asin = ?", [selected_asin])

        if dist_json:
            import json

            try:
                # Handle DuckDB returning dict or str
                if isinstance(dist_json, str):
                    data = json.loads(dist_json)
                else:
                    data = dist_json  # Already dict if DuckDB python client handles JSON type

                # Data: {"5": 70, "4": 10...}
                # Ensure keys are sorted 5->1
                sorted_keys = sorted(data.keys(), reverse=True)

                df_dist = pd.DataFrame(
                    {"Star Rating": [f"{k} Star" for k in sorted_keys], "Percentage": [data[k] for k in sorted_keys]}
                )

                st.plotly_chart(
                    px.pie(
                        df_dist,
                        names="Star Rating",
                        values="Percentage",
                        hole=0.4,
                        color_discrete_sequence=px.colors.sequential.RdBu_r,  # Reversed for 5 star = Blue
                        title="Market Reality (Population)",
                    ),
                    use_container_width=True,
                )
            except Exception as e:
                st.warning(f"Could not parse rating distribution: {e}")
        else:
            st.info("No rating breakdown available.")

    st.markdown("---")
    st.subheader("üìà Rating Trend over Time")
    if precalc and "rating_trend" in precalc:
        df_trend = pd.DataFrame(precalc["rating_trend"])
    else:
        df_trend = query_df(
            "SELECT DATE_TRUNC('month', review_date) as month, AVG(rating_score) as avg_score FROM reviews WHERE parent_asin = ? GROUP BY 1 ORDER BY 1",
            [selected_asin],
        )

    if not df_trend.empty:
        st.plotly_chart(
            px.line(
                df_trend,
                x="month",
                y="avg_score",
                markers=True,
                labels={"avg_score": "Average Rating", "month": "Date"},  # Renamed
            ),
            use_container_width=True,
        )

    # --- Evidence (Quotes) ---
    st.write("---")
    with st.expander("üîç View Evidence (Quotes)"):
        df_ev = get_evidence_data(selected_asin)
        if df_ev is not None and not df_ev.empty:
            st.dataframe(
                df_ev,
                use_container_width=True,
                column_config={
                    "Aspect (Status)": st.column_config.TextColumn("Aspect (Status)"),
                    "Evidence Quote": st.column_config.TextColumn("Quote", width="large"),
                },
                height=500,
            )
        else:
            st.info("No detailed quotes available.")


def render_mass_mode(selected_asin):
    st.subheader("üî• Market Sentiment Heatmap (Mass Mode)")

    # --- 1. SELECTION LOGIC ---
    base_info = query_df("SELECT brand, title, product_line, real_total_ratings FROM products WHERE asin = ?", [selected_asin])
    my_line = base_info.iloc[0]['product_line'] if not base_info.empty else None
    my_ratings = base_info.iloc[0]['real_total_ratings'] or 0

    # Get all potential candidates with ROBUST BRAND fetching
    all_parents = query_df("""
        SELECT parent_asin as asin, MAX(brand) as brand, ANY_VALUE(title) as title 
        FROM products 
        GROUP BY 1 
        ORDER BY MAX(real_total_ratings) DESC
    """)
    parent_list = all_parents['asin'].tolist()
    parent_map = all_parents.set_index('asin')['brand'].to_dict()

    line_filter = f"AND product_line = '{my_line}'" if my_line and my_line != 'None' else ""
    auto_candidates = query_df(f"""
        SELECT asin FROM products 
        WHERE asin != ? AND asin = parent_asin {line_filter}
        ORDER BY ABS(real_total_ratings - {my_ratings}) ASC LIMIT 15
    """, [selected_asin])['asin'].tolist()

    st.markdown("##### üõ†Ô∏è T√πy ch·ªânh danh s√°ch so s√°nh")
    selected_list = st.multiselect(
        "Ch·ªçn c√°c ASIN ƒë·ªëi th·ªß ƒë·ªÉ ƒë∆∞a v√†o b·∫£n ƒë·ªì nhi·ªát:",
        options=parent_list,
        default=[selected_asin] + auto_candidates,
        format_func=lambda x: f"{x} - {str(parent_map.get(x, 'Unknown Brand'))[:15]}...",
        key=f"mass_sel_list_v3_{selected_asin}"
    )

    if len(selected_list) < 2:
        st.info("Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 s·∫£n ph·∫©m ƒë·ªÉ so s√°nh.")
        return

    # --- 2. FETCH DATA IN BATCH ---
    sql = """
        SELECT p.asin, COALESCE(p.brand, 'Unknown') as brand, p.title, ps.metrics_json, p.real_total_ratings 
        FROM products p 
        JOIN product_stats ps ON p.asin = ps.asin 
        WHERE p.asin IN ({})
    """.format(','.join(['?']*len(selected_list)))
    df_batch = query_df(sql, selected_list)

    # --- 3. PROCESS HEATMAP DATA ---
    import json
    heatmap_data = []
    
    for _, row in df_batch.iterrows():
        try:
            m = json.loads(row["metrics_json"]) if isinstance(row["metrics_json"], str) else row["metrics_json"]
            brand_clean = row['brand'] if row['brand'] and row['brand'] != 'None' else 'Unknown'
            label = f"{brand_clean[:10]} ({row['asin']})"
            real_total = row['real_total_ratings'] or 0
            
            for item in m.get("sentiment_weighted", []):
                score = item["est_positive"] # Use Volume instead of %
                heatmap_data.append({
                    "S·∫£n ph·∫©m": label,
                    "ASIN": row['asin'],
                    "Kh√≠a c·∫°nh": item["aspect"],
                    "Kh√°ch khen (Est)": score,
                    "T·ªïng Rating": real_total
                })
        except: continue

    if not heatmap_data:
        st.warning("D·ªØ li·ªáu c·∫£m x√∫c ch∆∞a ƒë·ªß.")
        return

    df_hm = pd.DataFrame(heatmap_data)
    df_pivot = df_hm.pivot(index="Kh√≠a c·∫°nh", columns="S·∫£n ph·∫©m", values="Kh√°ch khen (Est)")
    
    # FIX: Fill NaN with 0 for missing aspects (Clean Heatmap)
    df_pivot = df_pivot.fillna(0)
    
    # Sort aspects by total volume of positive feedback across all products
    df_pivot = df_pivot.reindex(df_pivot.sum(axis=1).sort_values(ascending=False).index)

    # Create a mapping for total ratings to use in hover
    rating_map = df_hm.set_index("S·∫£n ph·∫©m")["T·ªïng Rating"].to_dict()

    # --- 4. RENDER HEATMAP ---
    fig = px.imshow(
        df_pivot,
        labels=dict(y="Kh√≠a c·∫°nh", x="S·∫£n ph·∫©m", color="Kh√°ch khen (Est)"),
        color_continuous_scale="YlGnBu", # Yellow-Green-Blue for density/volume
        aspect="auto",
        title="Market Strength Map (Weighted Volume)",
    )
    
    # Custom hover data: pass total ratings to the hovertemplate
    hover_ratings = [[rating_map.get(col, 0) for col in df_pivot.columns] for _ in range(len(df_pivot))]
    
    fig.update_traces(
        customdata=hover_ratings,
        hovertemplate="<b>%{x}</b><br>Kh√≠a c·∫°nh: %{y}<br>Kh√°ch khen: %{z:,.0f} ng∆∞·ªùi<br>T·ªïng Rating: %{customdata:,.0f}<extra></extra>"
    )
    fig.update_layout(height=max(500, len(df_pivot) * 25))
    st.plotly_chart(fig, use_container_width=True)

    # --- 5. QUICK DRILL-DOWN (INTERACTIVE) ---
    st.markdown("##### üöÄ Quick Drill-down")
    st.caption("Click v√†o m·ªôt d√≤ng ƒë·ªÉ chuy·ªÉn sang xem chi ti·∫øt s·∫£n ph·∫©m ƒë√≥.")
    
    df_summary = df_batch[['brand', 'asin', 'real_total_ratings']].copy()
    df_summary.columns = ['Brand', 'ASIN', 'Reviews']
    df_summary['Brand'] = df_summary['Brand'].fillna('Unknown')
    
    event = st.dataframe(
        df_summary,
        on_select="rerun",
        selection_mode="single-row",
        hide_index=True,
        use_container_width=True,
        key="jump_table_market"
    )

    if event and event.get("selection", {}).get("rows"):
        idx = event["selection"]["rows"][0]
        if idx < len(df_summary):
            target_asin = df_summary.iloc[idx]['ASIN']
            # Update Main Selector (Sidebar will pick this up on rerun)
            st.session_state["main_asin_selector"] = target_asin
            # Switch back to Single View
            st.session_state["xray_view_mode_final"] = "üì¶ T·ª´ng s·∫£n ph·∫©m"
            st.rerun()
